---
layout: post
title: "Neural Discrete Representation Learning"
description: 
categories: "论文"
---
## 摘要重点
- 问题： 无监督学习有用的（离散）表示很难 。

- 模型： 提出了 VQ-VAE（Vector Quantised-Variational AutoEncoder）。

- 关键点1： 编码器输出是离散的（discrete codes），而非连续的 。

- 关键点2： 先验是学习出来的（learnt prior），而非固定的 。

- 核心技术： 借鉴了向量量化（Vector Quantisation, VQ） 。

- 解决的痛点： 避免了 VAE 框架中常见的“后验坍塌”（posterior collapse）问题 。
>解码器太强大（如自回归解码器），解码器自身的能力足以完美地对数据 $p(x)$ 进行建模，导致模型完全忽略 (ignored) 潜在变量 $z$ 。换句话说，潜在变量没有学到数据中的任何有用信息，后验 $q(z|x)$ “崩溃”到与先验 $p(z)$ 无法区分

- 成果： 能生成高质量的图像、视频和语音
  
-------------------------
## Figure 1
![alt text](/images/posts/论文项目/image.png)
