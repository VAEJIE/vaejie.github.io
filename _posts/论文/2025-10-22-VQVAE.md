---
layout: post
title: "Neural Discrete Representation Learning"
description: 
categories: "论文"
---
### 模型：向量量化变分自编码器
#### 与VAE的差异：
1. 编码器输出是离散而不是连续（K个Zq中选一）
2. 先验是可学习的，而不是静态的

*VAE 的解码器接收的是一个无穷尽的连续空间里的点 Z；而 VQ-VAE 的解码器接收的只能是码本里那 K个（比如512个） Z_q 之一*

--------------------------------
## 痛点
- **后验坍塌**
- **离散VAE训练困难**
---------------------------------


## 阶段
#### 1.表征学习：
        1. 码本作为参数的一部分和编码器、解码器一起被训练
        2. 输入
        3. 编码，图片 X 通过编码器，生成一个（或一组）连续向量 Ze
        4. 量化（查表），在码本中选最接近Ze的那个Zq作为离散表征和对应的ID
        5. 用连续向量Zq解码
        6. 产生重构损失
        7. 反向传播计算误差：
           - 更新解码器
           - 更新编码器
           - 更新码本 
不断的迭代循环........得到很好的码本和编码器
#### 2. 先验学习
目的：得到一个离散Token（ID序列）生成器（**自回归先验模型**）。
只用上面👆已经训练好的的编码器把比如100万张图片过一遍
得到100万个正确的ID序列，这时训练一个新模型，目的是学习这些ID序列的“语法”和“概率”，它学习 $P(ID_n | ID_1, ..., ID_{n-1})$
    1. 数据喂给编码器得到Ze（**连续向量**）
    2. Ze去查码本，得到ID（**离散序列**）
        - 图片1 -> [42, 101, 5, 88, ...]
        - 图片2 -> [12, 99, 230, 17, ...]
            >为什么一个图片会分解为这么多ID的组成呢，因为每个ID对应的Zq表达的含义只是很细微的一部分，比如ID 42 对应的 Zq,42 可能代表了：“一种毛茸茸的、棕色的、带弧度的纹理”。ID 101 对应的 Zq,101 可能代表了：“一个尖锐的、高光在左上角的、类似眼睛的轮廓”
    3. 这些ID作为训练集
    4. 输入到自回归先验模型（Transformer/PixelCNN）
    5. 训练
    6. 通过新模型可以从无到有得到新序列
    7. 至此自回归先验模型训练成功
    8. 因为解码器只认连续向量，所以用离散ID序列去查码本得到连续向量序列
    9. 输入到解码器
    10. 解码成功
![alt text](/images/posts/论文项目/先验学习模型.png)

##### VQVAE（表征学习）只是一个重建系统，实现“压缩”和“解压”
-------------------------

## 创新点
    1. #### 核心设计： 可学习的、离散的码本
    2. #### 核心操作： 通过（argmin）最近邻查找，将Ze量化到码本的码字上
    3. #### 核心技巧： 通过STE（直通估计器）解决最近邻查找不可导问题
    4. #### 核心损失： 三部分的损失，解耦了Encoder、Decoder和Codebook三者的更新过程，确保它们各自向着正确的方向优化

















## Figure 1
![alt text](/images/posts/论文项目/VQVAE.png)
